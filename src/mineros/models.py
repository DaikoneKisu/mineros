import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

# --- Modelos y preprocesamiento ---
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

from mineros import load_models_data, k_prototypes_fit, find_optimal_k

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(
    page_title="Pipeline de Modelos de Machine Learning",
    page_icon="üéÆ",
    layout="wide"
)

# --- Cargar Datos ---
df_transactions, df_players = load_models_data()
df_transactions = df_transactions.rename(str, axis='columns')
df_players = df_players.rename(str, axis='columns')

# --- T√≠tulo Principal ---
st.title("üéÆ Pipeline de Modelos de Machine Learning para Gaming")
st.markdown("Una aplicaci√≥n para explorar segmentaci√≥n de clientes, reglas de asociaci√≥n y modelos predictivos.")

# --- Pesta√±as para cada modelo ---
tab1, tab2, tab3 = st.tabs(["üé≠ Agrupamiento (K-Prototypes)", "üìä Reglas de Asociaci√≥n (Apriori)", "üîÆ Predicci√≥n (Random Forest)"])

# =================================================================================================
# PESTA√ëA 1: K-PROTOTYPES
# =================================================================================================
with tab1:
    st.header("Segmentaci√≥n de Jugadores con K-Prototypes")

    with st.expander("Justificaci√≥n del Modelo", expanded=True):
        st.markdown("""
        El objetivo es segmentar usuarios en perfiles de comportamiento, lo cual es un problema de agrupamiento (clustering). El algoritmo **K-Prototypes** es la elecci√≥n ideal para esta tarea porque el conjunto de datos de los jugadores contiene una mezcla de tipos de datos. 
        - **Variables Num√©ricas:** `edad`, `gasto total`, `d√≠as de retenci√≥n`.
        - **Variables Categ√≥ricas:** `tipo de juego preferido`, `proveedor preferido`.

        K-Prototypes combina K-Means (para num√©ricas) y K-Modes (para categ√≥ricas), permitiendo agrupar a los usuarios de manera coherente y hol√≠stica para crear perfiles robustos y significativos.
        """)

    st.subheader("1. Entrenamiento y Validaci√≥n")
    st.markdown("Para encontrar el n√∫mero √≥ptimo de cl√∫steres (k), usamos el **M√©todo del Codo (Elbow Method)**, que mide el costo (disimilitud) para diferentes valores de k.")

    # Preparaci√≥n de datos para K-Prototypes
    data_for_clustering = df_players[['age', 'total_spent', 'retention_days', 'favorite_game_type', 'favorite_provider']].copy()

    # Identificar columnas categ√≥ricas por su √≠ndice
    categorical_indices = [data_for_clustering.columns.get_loc(col) for col in ['favorite_game_type', 'favorite_provider']]
    
    # Normalizar datos num√©ricos
    numerical_cols = ['age', 'total_spent', 'retention_days']
    scaler = StandardScaler()
    data_for_clustering[numerical_cols] = scaler.fit_transform(data_for_clustering[numerical_cols])
    
    matrix = data_for_clustering.to_numpy()

    k_range, costs = find_optimal_k(matrix, categorical_indices)

    # Gr√°fico del Codo
    fig_elbow = go.Figure()
    fig_elbow.add_trace(go.Scatter(x=list(k_range), y=costs, mode='lines+markers'))
    fig_elbow.update_layout(title='M√©todo del Codo para K-Prototypes',
                            xaxis_title='N√∫mero de Cl√∫steres (k)',
                            yaxis_title='Costo (Disimilitud)')
    st.plotly_chart(fig_elbow, use_container_width=True)

    st.info("El 'codo' (punto donde la curva se aplana) sugiere el n√∫mero √≥ptimo de cl√∫steres. Un valor com√∫n es 3, 4 o 5 para este tipo de an√°lisis.")

    st.subheader("2. An√°lisis de Cl√∫steres")
    k_optimal = st.slider("Selecciona el n√∫mero de cl√∫steres (k) para analizar:", 2, 7, 4)

    # Entrenar modelo final y asignar cl√∫steres
    clusters = k_prototypes_fit(matrix, categorical_indices, n_clusters=k_optimal).predict(matrix, categorical=categorical_indices)
    
    df_players['cluster'] = clusters
    data_for_clustering['cluster'] = clusters

    # Analizar los centroides
    cluster_analysis = df_players.groupby('cluster').agg(
        count=('player_id', 'size'),
        avg_age=('age', 'mean'),
        avg_total_spent=('total_spent', 'mean'),
        avg_retention_days=('retention_days', 'mean'),
        mode_game_type=('favorite_game_type', lambda x: x.mode()[0]),
        mode_provider=('favorite_provider', lambda x: x.mode()[0])
    ).reset_index()

    st.markdown(f"**Perfiles de los {k_optimal} clÁÖ§steres encontrados:**")
    st.dataframe(cluster_analysis.style.format({
        'avg_age': '{:.1f}',
        'avg_total_spent': '${:,.2f}',
        'avg_retention_days': '{:.1f} dÈìÜas'
    }))

    # Visualizaci√≥n de los cl√∫steres
    fig_clusters = px.scatter(df_players, 
                              x='total_spent', 
                              y='age', 
                              color='cluster',
                              hover_data=['name', 'favorite_game_type', 'retention_days'],
                              title=f'VisualizaciË¥∏n de {k_optimal} ClÁÖ§steres de Jugadores',
                              labels={'total_spent': 'Gasto Total (USD)', 'age': 'Edad', 'cluster': 'ClÁÖ§ster'})
    st.plotly_chart(fig_clusters, use_container_width=True)

# =================================================================================================
# PESTA√ëA 2: APRIORI
# =================================================================================================
with tab2:
    st.header("Descubrimiento de Reglas de Asociaci√≥n con Apriori")
    with st.expander("Justificaci√≥n del Modelo", expanded=True):
        st.markdown("""
        Para descubrir combinaciones de comportamientos recurrentes, se necesita una t√©cnica de reglas de asociaci√≥n, y el algoritmo **Apriori** es el est√°ndar de la industria para este fin. Este modelo es perfecto para analizar el "carrito de compras" de los juegos de un usuario.

        Nos permitir√° extraer reglas de negocio valiosas como, por ejemplo:
        - *"El 70% de los usuarios que juegan 'Slots' tambi√©n participan en 'Bingo'"* (confianza).
        - *"Los jugadores que prefieren 'Poker' y 'Blackjack' tienden a ser los que m√°s gastan"* (asociaci√≥n).

        El objetivo es identificar estas sinergias para potenciar estrategias de marketing cruzado.
        """)

    st.subheader("1. Preparaci√≥n de Datos")
    st.markdown("Para Apriori, necesitamos transformar los datos a un formato transaccional, donde cada fila es un jugador y las columnas indican los juegos que ha jugado.")
    
    # Crear lista de transacciones (juegos por jugador)
    transactions = df_transactions.groupby('player_id')['game_type'].apply(list).values.tolist()
    
    # Usar TransactionEncoder para obtener una matriz one-hot
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    df_onehot = pd.DataFrame(te_ary, columns=te.columns_) # pyright: ignore[reportArgumentType]

    with st.expander("Ver datos en formato transaccional (One-Hot)"):
        st.dataframe(df_onehot.head())

    st.subheader("2. Entrenamiento y ValidaciË¥∏n")
    st.markdown("""
    El "entrenamiento" implica ejecutar el algoritmo para generar reglas. La "validaciË¥∏n" se realiza ajustando las mËåÖtricas clave para filtrar solo las reglas mË∞©s relevantes.
    - **Soporte (Support):** Frecuencia con la que aparece un conjunto de juegos en todas las transacciones.
    - **Confianza (Confidence):** Probabilidad de que se juegue el juego B si ya se jugË¥∏ el juego A.
    - **Lift:** Mide la fuerza de la asociaciË¥∏n. Un lift > 1 indica una asociaciË¥∏n positiva.
    """)

    col1, col2 = st.columns(2)
    min_support = col1.slider("Selecciona el Soporte MÈìÜnimo (min_support):", 0.01, 0.2, 0.05)
    min_confidence = col2.slider("Selecciona la Confianza MÈìÜnima (min_confidence):", 0.1, 0.8, 0.3)

    # Aplicar Apriori
    frequent_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)
    
    if frequent_itemsets.empty:
        st.warning("No se encontraron conjuntos de ÈìÜtems frecuentes con el soporte actual. Intenta reducir el valor de 'Soporte MÈìÜnimo'.")
    else:
        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
        
        st.subheader("Reglas de AsociaciË¥∏n Encontradas")
        if rules.empty:
            st.warning("No se encontraron reglas con la confianza actual. Intenta reducir el valor de 'Confianza MÈìÜnima'.")
        else:
            # Limpiar y mostrar las reglas
            rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))
            rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))
            st.dataframe(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False))


# =================================================================================================
# PESTAËÑ©A 3: RANDOM FOREST
# =================================================================================================
with tab3:
    st.header("PredicciË¥∏n de Comportamiento con Random Forest Regressor")
    with st.expander("JustificaciË¥∏n del Modelo", expanded=True):
        st.markdown("""
        Para predecir el tiempo de retenciË¥∏n y el gasto futuro, necesitamos modelos de regresiË¥∏n. Se ha seleccionado **Random Forest** porque:
        - Es un modelo de *ensemble* robusto que **reduce el sobreajuste**.
        - Puede capturar **relaciones complejas y no lineales** entre las variables.
        - Proporciona la **importancia de las variables (feature importance)**, permitiendo identificar quËåÖ factores son los predictores mË∞©s fuertes.
        """)

    st.subheader("1. PreparaciË¥∏n de Datos y DivisiË¥∏n")
    
    target_variable = st.selectbox(
        "Selecciona la variable a predecir:",
        ('DÈìÜas de RetenciË¥∏n (retention_days)', 'Gasto Futuro (future_spend)')
    )
    
    target_col = 'retention_days' if 'RetenciË¥∏n' in target_variable else 'future_spend'
    
    # Preparar X e y
    features = ['age', 'total_spent', 'total_sessions', 'favorite_game_type', 'favorite_provider']
    X = df_players[features]
    y = df_players[target_col]

    # One-Hot Encoding para variables categË¥∏ricas
    X = pd.get_dummies(X, columns=['favorite_game_type', 'favorite_provider'], drop_first=True)

    # Dividir en entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    st.markdown(f"""
    - **Variable Objetivo (y):** `{target_col}`
    - **Variables Predictoras (X):** `{', '.join(features)}`
    - **TamaÂ∏Ωo del set de entrenamiento:** `{X_train.shape[0]} registros`
    - **TamaÂ∏Ωo del set de prueba:** `{X_test.shape[0]} registros`
    """)

    st.subheader("2. Entrenamiento y EvaluaciË¥∏n del Modelo")
    
    # Entrenar el modelo
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, oob_score=True)
    rf_model.fit(X_train, y_train)
    y_pred = rf_model.predict(X_test)

    # MËåÖtricas de evaluaciË¥∏n
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    oob = rf_model.oob_score_

    st.markdown("Resultados en el conjunto de prueba:")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Error Absoluto Medio (MAE)", f"{mae:.2f}")
    col2.metric("Error CuadrË∞©tico Medio (MSE)", f"{mse:.2f}")
    col3.metric("Coeficiente de DeterminaciË¥∏n (RËôè)", f"{r2:.2f}")
    col4.metric("Out-of-Bag (OOB) Score", f"{oob:.2f}", help="PuntuaciË¥∏n de validaciË¥∏n cruzada interna de Random Forest.")

    st.subheader("3. AnË∞©lisis de Resultados")
    col1, col2 = st.columns([1, 1])

    with col1:
        # GrË∞©fico de Predicciones vs. Valores Reales
        st.markdown("**Predicciones vs. Valores Reales**")
        fig_pred = go.Figure()
        fig_pred.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers', name='Predicciones'))
        fig_pred.add_trace(go.Scatter(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], 
                                      mode='lines', name='LÈìÜnea Ideal', line=dict(color='red', dash='dash')))
        fig_pred.update_layout(title='Valores Reales vs. Predichos',
                               xaxis_title='Valores Reales',
                               yaxis_title='Valores Predichos')
        st.plotly_chart(fig_pred, use_container_width=True)

    with col2:
        # GrË∞©fico de Importancia de Variables
        st.markdown("**Importancia de las Variables Predictoras**")
        importances = pd.DataFrame({'feature': X.columns, 'importance': rf_model.feature_importances_})
        importances = importances.sort_values('importance', ascending=True)
        
        fig_imp = px.bar(importances, 
                         x='importance', 
                         y='feature', 
                         orientation='h',
                         title='Importancia de cada variable en la predicciË¥∏n')
        st.plotly_chart(fig_imp, use_container_width=True)